{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d62b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import copy\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4701586",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "352b7c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "# Y = iris[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e414f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = PCA(n_components=2).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e215872b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def kmeans(X, K, max_iters=100):\n",
    "    # Initialize centroids randomly\n",
    "    centroids = X[np.random.choice(X.shape[0], K, replace=False), :]\n",
    "    labels = np.zeros(X.shape[0], dtype=int)\n",
    "    all_centroids = []\n",
    "    all_labels = []\n",
    "    # Run iterations until convergence or maximum iterations are reached\n",
    "    for i in range(max_iters):\n",
    "        # Assign each data point to the closest centroid\n",
    "        dists = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        labels = np.argmin(dists, axis=0)\n",
    "        \n",
    "        # Update centroids based on the mean of the data points in each cluster\n",
    "        for k in range(K):\n",
    "            centroids[k] = X[labels == k].mean(axis=0)\n",
    "        all_centroids.append(copy.deepcopy(centroids))\n",
    "        all_labels.append(labels[:])\n",
    "#         plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=100, c='r')\n",
    "#         plt.show()\n",
    "    return all_centroids,all_labels\n",
    "    \n",
    "\n",
    "all_centroids, all_labels = kmeans(Y, K=3)\n",
    "for i in range(100):\n",
    "    if i!=0 and np.array_equal(all_centroids[i],all_centroids[i-1]) and np.array_equal(all_labels[i],all_labels[i-1]):\n",
    "        break\n",
    "    centroids = all_centroids[i]\n",
    "    labels = all_labels[i]\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], c=labels)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=200, c='r',cmap=pylab.cm.terrain)\n",
    "    plt.savefig('Outputs/Kmeans/output'+str(i)+\".png\")\n",
    "    plt.clf()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ebc8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def affinity_propagation(X, max_iter=200, conv_threshold=1e-5, damping=0.9, verbose=False):\n",
    "    # Initialize variables\n",
    "    N = X.shape[0]\n",
    "    S = -np.sqrt(((X[:, np.newaxis, :] - X)**2).sum(axis=2))\n",
    "    A = np.zeros((N, N))\n",
    "    R = np.zeros((N, N))\n",
    "    messages = np.zeros((N, N, max_iter))\n",
    "    \n",
    "    # Run iterations\n",
    "    for i in range(max_iter):\n",
    "        # Compute responsibilities\n",
    "        Rp = R.copy()\n",
    "        A = damping * A + (1 - damping) * S\n",
    "        Y = A + Rp\n",
    "        idx = np.argmax(Y, axis=1)\n",
    "        max_val = Y[np.arange(N), idx]\n",
    "        Y[:, idx] = -np.inf\n",
    "        second_max = np.amax(Y, axis=1)\n",
    "        R = S - np.tile(np.maximum(max_val[:, np.newaxis], second_max), (1, N)).reshape((N, N), order='F') * (np.arange(N) != idx[:, np.newaxis])\n",
    "\n",
    "        \n",
    "        # Compute availabilities\n",
    "        Ap = A.copy()\n",
    "        np.fill_diagonal(R, np.diag(R) + np.diag(Ap))\n",
    "        Rbar = np.maximum(R, 0)\n",
    "        A = np.tile(np.sum(Rbar, axis=0), (N, 1)).T - Rbar\n",
    "        dA = np.diag(A)\n",
    "        A = np.minimum(A, 0)\n",
    "        np.fill_diagonal(A, dA)\n",
    "        \n",
    "        # Check for convergence\n",
    "        norm = np.linalg.norm(A - Ap) + np.linalg.norm(R - Rp)\n",
    "        if norm < conv_threshold:\n",
    "            break\n",
    "        \n",
    "        # Store messages\n",
    "        messages[:, :, i] = A + R\n",
    "        \n",
    "        # Print progress\n",
    "        if verbose:\n",
    "            print(\"Iteration\", i+1, \"- Number of clusters:\", len(np.where(np.diag(A + R) > 0)[0]))\n",
    "    \n",
    "    # Extract clusters\n",
    "    idx = np.where(np.diag(A + R) > 0)[0]\n",
    "    if len(idx) == 0:\n",
    "        return np.array([]), messages[:,:,:i]\n",
    "    clusters = []\n",
    "    for i in idx:\n",
    "        cluster = np.where(idx == i)[0]\n",
    "        clusters.append(cluster)\n",
    "    \n",
    "    return clusters, messages[:,:,:i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c13d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def dbscan(D, eps=0.5, MinPts=5):\n",
    "    '''\n",
    "    Cluster the dataset `D` using the DBSCAN algorithm.\n",
    "    \n",
    "    dbscan takes a dataset `D` (a list of vectors), a threshold distance\n",
    "    `eps`, and a required number of points `MinPts`.\n",
    "    \n",
    "    It will return a list of cluster labels. The label -1 means noise, and then\n",
    "    the clusters are numbered starting from 1.\n",
    "    '''\n",
    " \n",
    "    # This list will hold the final cluster assignment for each point in D.\n",
    "    # There are two reserved values:\n",
    "    #    -1 - Indicates a noise point\n",
    "    #     0 - Means the point hasn't been considered yet.\n",
    "    # Initially all labels are 0.    \n",
    "    labels = [0]*len(D)\n",
    "    all_labels = []\n",
    "    # C is the ID of the current cluster.    \n",
    "    C = 0\n",
    "    \n",
    "    # This outer loop is just responsible for picking new seed points--a point\n",
    "    # from which to grow a new cluster.\n",
    "    # Once a valid seed point is found, a new cluster is created, and the \n",
    "    # cluster growth is all handled by the 'expandCluster' routine.\n",
    "    \n",
    "    # For each point P in the Dataset D...\n",
    "    # ('P' is the index of the datapoint, rather than the datapoint itself.)\n",
    "    for P in range(0, len(D)):\n",
    "        # Only points that have not already been claimed can be picked as new \n",
    "        # seed points.    \n",
    "        # If the point's label is not 0, continue to the next point.\n",
    "        if not (labels[P] == 0):\n",
    "           continue\n",
    "        all_labels.append(copy.deepcopy(labels))\n",
    "        # Find all of P's neighboring points.\n",
    "        NeighborPts = region_query(D, P, eps)\n",
    "        \n",
    "        # If the number is below MinPts, this point is noise. \n",
    "        # This is the only condition under which a point is labeled \n",
    "        # NOISE--when it's not a valid seed point. A NOISE point may later \n",
    "        # be picked up by another cluster as a boundary point (this is the only\n",
    "        # condition under which a cluster label can change--from NOISE to \n",
    "        # something else).\n",
    "        if len(NeighborPts) < MinPts:\n",
    "            labels[P] = -1\n",
    "        # Otherwise, if there are at least MinPts nearby, use this point as the \n",
    "        # seed for a new cluster.    \n",
    "        else: \n",
    "           C += 1\n",
    "           grow_cluster(D, labels, P, NeighborPts, C, eps, MinPts)\n",
    "    \n",
    "    # All data has been clustered!\n",
    "    return all_labels\n",
    "\n",
    "\n",
    "def grow_cluster(D, labels, P, NeighborPts, C, eps, MinPts):\n",
    "    '''\n",
    "    Grow a new cluster with label `C` from the seed point `P`.\n",
    "    \n",
    "    This function searches through the dataset to find all points that belong\n",
    "    to this new cluster. When this function returns, cluster `C` is complete.\n",
    "    \n",
    "    Parameters:\n",
    "      `D`      - The dataset (a list of vectors)\n",
    "      `labels` - List storing the cluster labels for all dataset points\n",
    "      `P`      - Index of the seed point for this new cluster\n",
    "      `NeighborPts` - All of the neighbors of `P`\n",
    "      `C`      - The label for this new cluster.  \n",
    "      `eps`    - Threshold distance\n",
    "      `MinPts` - Minimum required number of neighbors\n",
    "    '''\n",
    "\n",
    "    # Assign the cluster label to the seed point.\n",
    "    labels[P] = C\n",
    "    \n",
    "    # Look at each neighbor of P (neighbors are referred to as Pn). \n",
    "    # NeighborPts will be used as a FIFO queue of points to search--that is, it\n",
    "    # will grow as we discover new branch points for the cluster. The FIFO\n",
    "    # behavior is accomplished by using a while-loop rather than a for-loop.\n",
    "    # In NeighborPts, the points are represented by their index in the original\n",
    "    # dataset.\n",
    "    i = 0\n",
    "    while i < len(NeighborPts):    \n",
    "        \n",
    "        # Get the next point from the queue.        \n",
    "        Pn = NeighborPts[i]\n",
    "       \n",
    "        # If Pn was labelled NOISE during the seed search, then we\n",
    "        # know it's not a branch point (it doesn't have enough neighbors), so\n",
    "        # make it a leaf point of cluster C and move on.\n",
    "        if labels[Pn] == -1:\n",
    "           labels[Pn] = C\n",
    "        \n",
    "        # Otherwise, if Pn isn't already claimed, claim it as part of C.\n",
    "        elif labels[Pn] == 0:\n",
    "            # Add Pn to cluster C (Assign cluster label C).\n",
    "            labels[Pn] = C\n",
    "            \n",
    "            # Find all the neighbors of Pn\n",
    "            PnNeighborPts = region_query(D, Pn, eps)\n",
    "            \n",
    "            # If Pn has at least MinPts neighbors, it's a branch point!\n",
    "            # Add all of its neighbors to the FIFO queue to be searched. \n",
    "            if len(PnNeighborPts) >= MinPts:\n",
    "                NeighborPts = NeighborPts + PnNeighborPts\n",
    "            # If Pn *doesn't* have enough neighbors, then it's a leaf point.\n",
    "            # Don't queue up it's neighbors as expansion points.\n",
    "            #else:\n",
    "                # Do nothing                \n",
    "                #NeighborPts = NeighborPts               \n",
    "        \n",
    "        # Advance to the next point in the FIFO queue.\n",
    "        i += 1        \n",
    "    \n",
    "    # We've finished growing cluster C!\n",
    "\n",
    "\n",
    "def region_query(D, P, eps):\n",
    "    '''\n",
    "    Find all points in dataset `D` within distance `eps` of point `P`.\n",
    "    \n",
    "    This function calculates the distance between a point P and every other \n",
    "    point in the dataset, and then returns only those points which are within a\n",
    "    threshold distance `eps`.\n",
    "    '''\n",
    "    neighbors = []\n",
    "    \n",
    "    # For each point in the dataset...\n",
    "    for Pn in range(0, len(D)):\n",
    "        \n",
    "        # If the distance is below the threshold, add it to the neighbors list.\n",
    "        if numpy.linalg.norm(D[P] - D[Pn]) < eps:\n",
    "           neighbors.append(Pn)\n",
    "            \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0bb893d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_labels = dbscan(Y)\n",
    "for i in range(len(all_labels)):\n",
    "    labels = all_labels[i]\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], c=labels,cmap=pylab.cm.terrain)\n",
    "    plt.savefig('Outputs/DBScan/output'+str(i)+\".png\")\n",
    "    plt.clf()\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
